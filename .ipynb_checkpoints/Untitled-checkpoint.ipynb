{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69263752-9300-4e0f-b024-0fc0aebff060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words for Label 0:\n",
      "[('work', 1333.3653846161308), ('miss', 1112.1485382882022), ('want', 1036.4553195957162), ('today', 1007.8550636274665), ('sad', 995.4761172544956), ('really', 922.5046922936124), ('going', 914.5355797564155), ('wish', 829.2407574065577), ('know', 796.1591348806766), ('sorry', 759.4864034546129), ('time', 744.1179521057421), ('good', 730.47953932828), ('home', 728.8617696036015), ('oh', 718.1051067115317), ('feel', 717.5006944265702), ('bad', 689.2460326236932), ('need', 688.8217472763345), ('didnt', 654.1969682801148), ('think', 639.0556681055214), ('sleep', 621.1451915134836)]\n",
      "\n",
      "Most common words for Label 1:\n",
      "[('good', 1729.2745383590425), ('love', 1435.5672123183656), ('thanks', 1426.0209102112717), ('lol', 1030.6625781265848), ('going', 895.9255892010035), ('time', 868.6139667189424), ('great', 848.0968033762986), ('new', 805.6775873850534), ('today', 791.1205217066893), ('know', 777.2332973029571), ('thank', 738.5427906134265), ('happy', 715.011799374031), ('haha', 685.0632819063582), ('night', 672.2088524334697), ('morning', 666.3998335335149), ('twitter', 646.4120607660607), ('fun', 637.7490271452489), ('think', 625.5874153722358), ('nice', 617.3039975075777), ('hope', 595.6625993764944)]\n",
      "\n",
      "\n",
      "Train Accuracy: 0.76\n",
      "Evaluation Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "\n",
    "train=pd.read_csv(\"train_dataset.csv\")\n",
    "test=pd.read_csv(\"test_dataset.csv\")\n",
    "vaal=pd.read_csv(\"val_dataset.csv\")\n",
    "mod=LogisticRegression(max_iter=5000)\n",
    "#print(\"\\nMissing values:\\n\", train.isnull().sum())\n",
    "#sns.countplot(x='Label', data=train, palette='viridis')\n",
    "#plt.title('Label distr')\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "def common_distr(feature_names, matrix, n=20):\n",
    "    sums = matrix.sum(axis=0)\n",
    "    words_scores = [(feature_names[idx], sums[0, idx]) for idx in range(len(feature_names))]   #τα feature names είναι tokenized words και για\n",
    "                                                                                        #καθεναμ=, το σκορ είναι το αθροισμα τωνφορων που εμφανιζεται\n",
    "    words_scores = sorted(words_scores, key=lambda x: x[1], reverse=True)\n",
    "    return words_scores[:n]\n",
    "\n",
    "def plot_balance():\n",
    "    train0=len(train[train[\"Label\"]==0])\n",
    "    train1=len(train[train[\"Label\"]==1])\n",
    "    print(train0)\n",
    "    \n",
    "\n",
    "def plot_length_distr():\n",
    "    train[\"Text_len\"]=train[\"Text\"].apply(len)\n",
    "    #print(train)\n",
    "    plt.figure(figsize=(12,5))\n",
    "    sns.histplot(train[train['Label']==0]['Text_len'], bins=30, color='red', label='Label 0', kde=True )\n",
    "    sns.histplot(train[train['Label']==1]['Text_len'], bins=30, color='green', label='Label 1', kde=True )\n",
    "    plt.title(\"0 vs 1 length distribution\")\n",
    "    plt.ylabel(\"tweets\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "def workcloud(label, color):\n",
    "    \n",
    "    text = \" \".join(train[train['Label'] == label]['Text_processed'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', colormap=color).generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Word Cloud for Category {label}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def analysis_before_preprocess():\n",
    "    plot_balance()\n",
    "    plot_length_distr\n",
    "\n",
    "\n",
    "def preprocess(txt):\n",
    "    txt=txt.lower()\n",
    "    txt=re.sub(r'http\\S+', '', txt) #remove links\n",
    "    txt=re.sub(r'@\\w+', '', txt)   #remove mentions\n",
    "    txt = re.sub(r'[^\\w\\s]', '', txt)  # Remove !/? klp...\n",
    "    #must tokenize words\n",
    "\n",
    "    #Do stemming / lemmat\n",
    "    \n",
    " \n",
    "    return txt\n",
    "    \n",
    "def print_common_words(matrix0, matrix1):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    common_words_0=common_distr(feature_names, matrix0)\n",
    "    common_words_1=common_distr(feature_names, matrix1)\n",
    "    print(\"Most common words for Label 0:\")\n",
    "    print(common_words_0)\n",
    "    print(\"\\nMost common words for Label 1:\")\n",
    "    print(common_words_1)\n",
    "\n",
    "\n",
    "#Adding some words in the stopwords list since i saw that these are frequently used\n",
    "default_stopwords = _stop_words.ENGLISH_STOP_WORDS\n",
    "stopwords = {'im', 'ive', 'dont', 'wont', 'cant', 'isnt', 'doesnt', 'just', 'like', 'got', 'day'}\n",
    "custom_stopwords = set(default_stopwords) | stopwords\n",
    "\n",
    "def process():\n",
    "    analysis_before_preprocessing()\n",
    "    train['Text_processed']=train['Text'].apply(preprocess)  #preprocess text\n",
    "    vaal['Text_processed']=vaal['Text'].apply(preprocess)\n",
    "    #then vectorize it, both training and evaluation data sets\n",
    "    vectorizer = TfidfVectorizer(stop_words=list(custom_stopwords), max_features=3000)\n",
    "    Xtrain=vectorizer.fit_transform(train['Text_processed'])  #FEAUture matrix, has \"documents\" as rows and each col is a word? \n",
    "    Xval=vectorizer.transform(vaal['Text_processed'])\n",
    "    ytrain=train['Label']\n",
    "    yval=vaal['Label']\n",
    "    #Splitting the categories of the train data set\n",
    "    matrix0=Xtrain[train['Label']==0]\n",
    "    matrix1=Xtrain[train['Label']==1]\n",
    "    \n",
    "\n",
    "\n",
    "#workcloud(1, 'Greens')\n",
    "#workcloud(0, 'Blues')\n",
    "\n",
    "\n",
    "def print_stats(name, y,ypred):\n",
    "    accuracy_v = accuracy_score(y, ypred)\n",
    "    #precision_v = precision_score(yval, y_val_pred)\n",
    "    #recall_v = recall_score(yval, y_val_pred)\n",
    "    #f1_v = f1_score(yval, y_val_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "    #print(f\"Validation Precision: {precision:.2f}\")\n",
    "    #print(f\"Validation Recall: {recall:.2f}\")\n",
    "    #print(f\"Validation F1-Score: {f1:.2f}\")\n",
    "    conf_matrix = confusion_matrix(y, ypred)\n",
    "'''  \n",
    " print(f\"{name} Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "                yticklabels=['Actual 0', 'Actual 1'])\n",
    "    plt.title(\"Confusion Matrix Heatmap\")\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.show()\n",
    "'''\n",
    "mod.fit(Xtrain, ytrain)  #trainig\n",
    "y_train_pred=mod.predict(Xtrain)\n",
    "y_val_pred=mod.predict(Xval) #evaluation\n",
    "print_stats(\"\\n\\nTrain\", ytrain, y_train_pred)\n",
    "print_stats(\"Evaluation\", yval, y_val_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
